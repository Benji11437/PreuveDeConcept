import streamlit as st
import pandas as pd
import nltk
from collections import Counter
from nltk.corpus import stopwords
import plotly.express as px
import altair as alt
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# ===============================
# CONFIGURATION DE LA PAGE
# ===============================
st.set_page_config(page_title="Dashboard Tweets", layout="wide")

st.title("üìä Dashboard ‚Äì Analyse descriptive des tweets")
st.markdown(
    "Analyse exploratoire des tweets : structure du jeu de donn√©es, "
    "distribution des sentiments et analyse lexicale."
)

# ===============================
# CHARGEMENT DES DONN√âES
# ===============================
df = pd.read_csv("data/df_c.csv")
df = df.rename(columns={"lemmatize_joined": "text"})

# S√©curisation
df["text"] = df["text"].fillna("").astype(str)

# ===============================
# APER√áU DES DONN√âES
# ===============================
st.subheader("üîç Aper√ßu des donn√©es")
st.dataframe(df.head(), use_container_width=True)

# ===============================
# KPIs GLOBAUX
# ===============================
st.subheader("Indicateurs cl√©s")

col1, col2, col3 = st.columns(3)

col1.metric("Nombre total de tweets", len(df))
col2.metric(
    "Longueur moyenne (caract√®res)",
    round(df["text"].str.len().mean(), 1)
)
col3.metric("Nombre de cat√©gories", df["target"].nunique())


# ===============================
# PR√âTRAITEMENT NLP
# ===============================
nltk.download("stopwords")
stop_words = set(stopwords.words("english"))

df["nb_words"] = df["text"].apply(lambda x: len(x.split()))

def clean_tokens(text):
    return [
        w.lower()
        for w in text.split()
        if w.isalpha() and w.lower() not in stop_words
    ]

tokens = df["text"].apply(clean_tokens).sum()
word_freq = Counter(tokens).most_common(20)
top_words = [w for w, _ in word_freq]

# ===============================
# ANALYSE TEXTUELLE ‚Äì ONGLET
# ===============================
st.subheader("Analyse textuelle d√©taill√©e")

tab1, tab2, tab3 = st.tabs(
    ["üìà Longueur des tweets", "üìä Lexique & mots", "‚òÅÔ∏è WordCloud"]
)

# ---------- ONGLET 1
with tab1:
    st.markdown("Distribution du nombre de mots par tweet.")

    fig_hist = px.histogram(
        df,
        x="nb_words",
        nbins=20,
        labels={"nb_words": "Nombre de mots"},
        title="Distribution de la longueur des tweets"
    )
    fig_hist.update_layout(
        template="plotly_white",
        xaxis_title="Nombre de mots",
        yaxis_title="Nombre de tweets"
    )
    st.plotly_chart(fig_hist, use_container_width=True)

    fig_box = px.box(
        df,
        x="target",
        y="nb_words",
        color="target",
        labels={"nb_words": "Nombre de mots"},
        title="Longueur des tweets par sentiment",
        color_discrete_map={
            "Positif": "#1b9e77",
            "N√©gatif": "#d95f02"
        }
    )
    st.plotly_chart(fig_box, use_container_width=True)

# ---------- ONGLET 2
with tab2:
    st.markdown("Mots les plus fr√©quents apr√®s suppression des stopwords.")

    df_words = pd.DataFrame(word_freq, columns=["Mot", "Fr√©quence"])

    chart_bar = alt.Chart(df_words).mark_bar().encode(
        x=alt.X("Fr√©quence:Q", title="Fr√©quence"),
        y=alt.Y("Mot:N", sort="-x", title="Mot"),
        tooltip=["Mot", "Fr√©quence"]
    ).properties(
        title="Top 20 des mots les plus fr√©quents"
    )

    st.altair_chart(chart_bar, use_container_width=True)

# ---------- ONGLET 3
with tab3:
    st.markdown(
        "Nuage de mots repr√©sentant visuellement les termes les plus fr√©quents."
    )

    wc = WordCloud(
        background_color="white",
        colormap="viridis",
        width=700,
        height=400
    ).generate(" ".join(tokens))

    fig_wc, ax = plt.subplots()
    ax.imshow(wc, interpolation="bilinear")
    ax.axis("off")

    st.pyplot(fig_wc)
